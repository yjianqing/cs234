{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from baselines.common.vec_env.vec_frame_stack import VecFrameStack\n",
    "from baselines.common.cmd_util import make_atari_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"AssaultNoFrameskip-v0\"#\"DemonAttackNoFrameskip-v0\"\n",
    "TRAIN_FOLDER = 'assault_ppo_seed_0/' # './demon_attack_seed_0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_FOLDER + \"make_model.pkl\", \"rb\") as f:\n",
    "    make_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patcho/cs234/baselines/common/distributions.py:134: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "WARNING:tensorflow:From /home/patcho/cs234/baselines/common/distributions.py:145: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/patcho/cs234/baselines/common/distributions.py:147: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "tf.Session().__enter__()\n",
    "\n",
    "model = make_model()\n",
    "model.load(TRAIN_FOLDER + 'checkpoints/00001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.0\n",
      "1000: 3.3218373665927925\n",
      "2000: 2.1431640720420986\n",
      "3000: 1.6666413408799923\n",
      "4000: 2.60309831414932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-67:\n",
      "Process Process-66:\n",
      "Process Process-71:\n",
      "Process Process-68:\n",
      "Process Process-65:\n",
      "Traceback (most recent call last):\n",
      "Process Process-72:\n",
      "Process Process-69:\n",
      "Process Process-70:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9cd88eac3f6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneglogpacs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_reward\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs234/baselines/common/vec_env/__init__.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs234/baselines/common/vec_env/vec_frame_stack.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstackedobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstackedobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs234/baselines/common/vec_env/subproc_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mremote\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaiting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs234/baselines/common/vec_env/subproc_vec_env.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mremote\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaiting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/patcho/cs234/baselines/common/vec_env/subproc_vec_env.py\", line 10, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/patcho/cs234/baselines/common/vec_env/subproc_vec_env.py\", line 10, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/patcho/cs234/baselines/common/vec_env/subproc_vec_env.py\", line 12, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/patcho/cs234/baselines/common/vec_env/subproc_vec_env.py\", line 12, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "  File \"/home/patcho/cs234/baselines/common/vec_env/subproc_vec_env.py\", line 12, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "  File \"/home/patcho/cs234/baselines/common/vec_env/subproc_vec_env.py\", line 12, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/patcho/cs234/baselines/common/vec_env/subproc_vec_env.py\", line 10, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/core.py\", line 330, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/core.py\", line 330, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/common/vec_env/subproc_vec_env.py\", line 12, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/core.py\", line 330, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/core.py\", line 330, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/core.py\", line 313, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/core.py\", line 313, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/core.py\", line 330, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/core.py\", line 313, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/core.py\", line 313, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 55, in step\n",
      "    return self.env.step(ac)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 55, in step\n",
      "    return self.env.step(ac)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/core.py\", line 313, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 55, in step\n",
      "    return self.env.step(ac)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 67, in step\n",
      "    obs, reward, done, info = self.env.step(action)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 55, in step\n",
      "    return self.env.step(ac)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 67, in step\n",
      "    obs, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 67, in step\n",
      "    obs, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 55, in step\n",
      "    return self.env.step(ac)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 67, in step\n",
      "    obs, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/bench/monitor.py\", line 57, in step\n",
      "    ob, rew, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 67, in step\n",
      "    obs, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 109, in step\n",
      "    obs, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/bench/monitor.py\", line 57, in step\n",
      "    ob, rew, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 109, in step\n",
      "    obs, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/bench/monitor.py\", line 57, in step\n",
      "    ob, rew, done, info = self.env.step(action)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/patcho/cs234/baselines/bench/monitor.py\", line 57, in step\n",
      "    ob, rew, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 109, in step\n",
      "    obs, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/bench/monitor.py\", line 57, in step\n",
      "    ob, rew, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 35, in step\n",
      "    return self.env.step(ac)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 35, in step\n",
      "    return self.env.step(ac)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 35, in step\n",
      "    return self.env.step(ac)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 109, in step\n",
      "    obs, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/wrappers/time_limit.py\", line 31, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/wrappers/time_limit.py\", line 31, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/envs/atari/atari_env.py\", line 77, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/envs/atari/atari_env.py\", line 78, in step\n",
      "    ob = self._get_obs()\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/wrappers/time_limit.py\", line 31, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 109, in step\n",
      "    obs, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/envs/atari/atari_env.py\", line 96, in _get_obs\n",
      "    img = self._get_image()\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 35, in step\n",
      "    return self.env.step(ac)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/envs/atari/atari_env.py\", line 83, in _get_image\n",
      "    return self.ale.getScreenRGB2()\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/atari_py/ale_python_interface.py\", line 221, in getScreenRGB2\n",
      "    ale_lib.getScreenRGB2(self.obj, as_ctypes(screen_data[:]))\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/wrappers/time_limit.py\", line 31, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/envs/atari/atari_env.py\", line 77, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/patcho/cs234/baselines/common/atari_wrappers.py\", line 35, in step\n",
      "    return self.env.step(ac)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/atari_py/ale_python_interface.py\", line 136, in act\n",
      "    return ale_lib.act(self.obj, int(action))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/envs/atari/atari_env.py\", line 77, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/atari_py/ale_python_interface.py\", line 136, in act\n",
      "    return ale_lib.act(self.obj, int(action))\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/wrappers/time_limit.py\", line 31, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/atari_py/ale_python_interface.py\", line 136, in act\n",
      "    return ale_lib.act(self.obj, int(action))\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/gym/envs/atari/atari_env.py\", line 77, in step\n",
      "    reward += self.ale.act(action)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/patcho/.local/lib/python3.5/site-packages/atari_py/ale_python_interface.py\", line 136, in act\n",
      "    return ale_lib.act(self.obj, int(action))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "nenv = 8\n",
    "env = VecFrameStack(make_atari_env(ENV_NAME, nenv, 0), 4)\n",
    "\n",
    "nsteps = 1\n",
    "gamma = 0.99\n",
    "lam = 0.95\n",
    "\n",
    "obs = np.zeros((nenv,) + env.observation_space.shape, dtype=model.train_model.X.dtype.name)\n",
    "obs[:] = env.reset()\n",
    "states = model.initial_state\n",
    "dones = [False for _ in range(nenv)]\n",
    "\n",
    "NUM_STEPS = 100000\n",
    "\n",
    "total_reward = 0\n",
    "for i in range(NUM_STEPS):\n",
    "    actions, values, states, neglogpacs = model.step(obs, states, dones)\n",
    "    obs[:], rewards, dones, infos = env.step(actions)\n",
    "    total_reward  rewards[0]\n",
    "    if dones[0] == 1:\n",
    "        print total_reward\n",
    "        total_reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
